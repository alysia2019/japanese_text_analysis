{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from PIL import Image as pi\n",
    "from ipywidgets import HBox, VBox, Layout, HTML\n",
    "from ipywidgets import Image as Image_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from fastai.vision import *\n",
    "    from fastai.metrics import error_rate\n",
    "    fastai_imported = True\n",
    "except Exception as ex:\n",
    "    print('Switch to fastapi-cpu kernel.')\n",
    "    fastai_imported = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ray/data/kmnist/t10k-images-idx3-ubyte', 'rb') as f:\n",
    "    magic, size = struct.unpack(\">II\", f.read(8))\n",
    "    nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
    "    data = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "    data = data.reshape((size, nrows, ncols))\n",
    "\n",
    "print(magic, size, nrows, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [pi.fromarray(data[n,:,:]) for n in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for n in range(len(data)):\n",
    "    b = BytesIO()\n",
    "    im = pi.fromarray(data[n,:,:])\n",
    "    im.save(b, format='png')\n",
    "    images.append(b.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of relearned kanji images.\n",
    "z_container_layout = Layout(border='0px solid  grey', width='50px', length='50px', margin='0px 0px 0px 0px')\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='flex-start')\n",
    "c_container_layout = Layout(border='0px solid black', width='50%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig1 = VBox(children=[HBox(children=[VBox(children=[Image_widget(value=image, layout=z_container_layout)], layout=a_container_layout) \n",
    "                     for image in images[10*m:10*m+10]], layout=b_container_layout) for m in range(13)], layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ray/data/kmnist/t10k-labels-idx1-ubyte', 'rb') as f:\n",
    "    magic, size = struct.unpack(\">II\", f.read(8))\n",
    "    labels = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "\n",
    "print(magic, size, nrows, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of labels.\n",
    "hiragana = ['お', 'き', 'す', 'つ', 'な', 'は', 'ま', 'や', 'れ', 'を']\n",
    "h_labels = [hiragana[l] for l in labels]\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='space-between')\n",
    "c_container_layout = Layout(border='0px solid black', width='50%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig2 = VBox(children=[HBox(children=[HBox(children=[HTML(value=str(label))], layout=a_container_layout) \n",
    "                     for label in h_labels[no_boxes_per_line*m:no_boxes_per_line*m+no_boxes_per_line]], layout=b_container_layout) for m in range(13)],\n",
    "     layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HBox(children=[fig1, fig2], layout=Layout(border='0px solid black', justify_content='space-around'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /Users/ray/data/kmnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_images = []\n",
    "for label in [0, 2]:\n",
    "    subscripts = [n for n,l in enumerate(labels) if l == label]\n",
    "    character_images.extend([images[n] for n in subscripts[0:30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of relearned kanji images.\n",
    "z_container_layout = Layout(border='0px solid  grey', width='80px', length='80px', margin='0px 0px 0px 0px')\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='flex-start')\n",
    "c_container_layout = Layout(border='0px solid black', width='100%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig1 = VBox(children=[HBox(children=[VBox(children=[Image_widget(value=image, layout=z_container_layout)], layout=a_container_layout) \n",
    "                     for image in character_images[30*m:30*m+30]], layout=b_container_layout) for m in range(10)], layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of relearned kanji images.\n",
    "z_container_layout = Layout(border='0px solid  grey', width='80px', length='80px', margin='0px 0px 0px 0px')\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='flex-start')\n",
    "c_container_layout = Layout(border='0px solid black', width='30%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig1 = VBox(children=[HBox(children=[VBox(children=[Image_widget(value=image, layout=z_container_layout)], layout=a_container_layout) \n",
    "                     for image in character_images[10*m:10*m+10]], layout=b_container_layout) for m in range(10)], layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = BytesIO()\n",
    "im = pi.open('images/200014735/image/200014735_00014.jpg')\n",
    "im.save(b, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = (1000, 820, 5300, 2950)\n",
    "region = im.crop(box)\n",
    "imgByteArr = BytesIO()\n",
    "region.save(imgByteArr, format='PNG')\n",
    "imgByteArr = imgByteArr.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HBox(children=[fig1, VBox(children=[Image_widget(value=imgByteArr)], layout=Layout(width='60%'))], layout=Layout(border='0px solid black', justify_content='space-around'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['お', 'き', 'す', 'つ', 'な', 'は', 'ま', 'や', 'れ', 'を']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('/Users/ray/.fastai/data/mnist_sample/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = DATA_PATH / 'labels.csv'\n",
    "!head {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /Users/ray/data/kmnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    metadata = []\n",
    "    with open('/Users/ray/data/kmnist/t10k-labels-idx1-ubyte', 'rb') as f:\n",
    "        magic, size = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "\n",
    "    with open('/Users/ray/data/kmnist/t10k-images-idx3-ubyte', 'rb') as f:\n",
    "        magic, size = struct.unpack(\">II\", f.read(8))\n",
    "        nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
    "        data = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "        data = data.reshape((size, nrows, ncols))\n",
    "\n",
    "    for n,label in zip(range(len(data)), labels):\n",
    "        im = pi.fromarray(data[n,:,:])\n",
    "        outfile = 'kmnist/valid/' + str(n) + '.png'\n",
    "        im.save(outfile, format='png')\n",
    "        metadata.append([outfile, label])\n",
    "\n",
    "    # Now Training data.\n",
    "    with open('/Users/ray/data/kmnist/train-labels-idx1-ubyte', 'rb') as f:\n",
    "        magic, size = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "\n",
    "    with open('/Users/ray/data/kmnist/train-images-idx3-ubyte', 'rb') as f:\n",
    "        magic, size = struct.unpack(\">II\", f.read(8))\n",
    "        nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
    "        data = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "        data = data.reshape((size, nrows, ncols))\n",
    "\n",
    "    for n,label in zip(range(len(data)), labels):\n",
    "        im = pi.fromarray(data[n,:,:])\n",
    "        outfile = 'kmnist/train/' + str(n) + '.png'\n",
    "        im.save(outfile, format='png')\n",
    "        metadata.append([outfile, label])\n",
    "\n",
    "    metadata_df = pd.DataFrame(metadata, columns=['name', 'label'])\n",
    "    metadata_df['name'] = metadata_df.name.str.replace('kmnist/', '')\n",
    "    metadata_df.to_csv('kmnist/labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fastai_imported == True:\n",
    "    data = ImageDataBunch.from_csv('/Users/ray/scratch/japanese_text_analysis/notebooks/kmnist/')\n",
    "    data.show_batch(rows=3, figsize=(5,5))\n",
    "    learn = cnn_learner(data, models.resnet50, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fastai_imported == True:\n",
    "    if not learn.load('kmnist-stage-1-50'):\n",
    "        print('Could not load model, training instead.')\n",
    "        learn.fit(4)\n",
    "        learn.save('kmnist-stage-1-50');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fastai_imported == True:\n",
    "    interp = ClassificationInterpretation.from_learner(learn)\n",
    "    losses,idxs = interp.top_losses()\n",
    "    len(data.valid_ds)==len(losses)==len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fastai_imported == True:\n",
    "    interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fastai_imported == True:\n",
    "    interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:japanese_text_analysis] *",
   "language": "python",
   "name": "conda-env-japanese_text_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
