{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# くずし字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMNIST Data Setup\n",
    "\n",
    "くずし字　[KMNIST Dataset description](http://codh.rois.ac.jp/kmnist/)\n",
    "\n",
    "[Resources for hentaigana](https://wakancambridge.files.wordpress.com/2017/05/useful-resources-for-the-study-of-hentaigana-with-recommended1.pdf)\n",
    "<img src=\"images/hentaigana.png\" alt=\"hentaigana chart\" width=\"48%\" align=\"left\"/>\n",
    "\n",
    "[Dataset on github:](https://github.com/rois-codh/kmnist)\n",
    "\n",
    "| File            | Examples | Download (MNIST format)    | Download (NumPy format)      |\n",
    "|-----------------|--------------------|----------------------------|------------------------------|\n",
    "| Training images | 60,000             | [train-images-idx3-ubyte.gz](http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz) (18MB) | [kmnist-train-imgs.npz](http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-imgs.npz) (18MB)   |\n",
    "| Training labels | 60,000             | [train-labels-idx1-ubyte.gz](http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz) (30KB) | [kmnist-train-labels.npz](http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-labels.npz) (30KB)  |\n",
    "| Testing images  | 10,000             | [t10k-images-idx3-ubyte.gz](http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz) (3MB) | [kmnist-test-imgs.npz](http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-imgs.npz) (3MB)   |\n",
    "| Testing labels  | 10,000             | [t10k-labels-idx1-ubyte.gz](http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz) (5KB)  | [kmnist-test-labels.npz](http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-labels.npz) (5KB) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import gzip\n",
    "\n",
    "import struct\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from PIL import Image as pi\n",
    "from ipywidgets import HBox, VBox, Layout, HTML\n",
    "from ipywidgets import Image as Image_widget\n",
    "\n",
    "try:\n",
    "    from fastai.vision import *\n",
    "    from fastai.metrics import error_rate\n",
    "    fastai_imported = True\n",
    "except Exception as ex:\n",
    "    print('Switch to fastapi-cpu kernel to train model.')\n",
    "    fastai_imported = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"../data/raw\")\n",
    "PATH = DATA_PATH / \"kmnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://codh.rois.ac.jp/kmnist/dataset/kmnist/\"\n",
    "FILENAMES = ['train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz', \n",
    "             't10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "for FILENAME in FILENAMES:\n",
    "    if not (PATH / FILENAME).exists():\n",
    "            content = requests.get(URL + FILENAME).content\n",
    "            (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kmnist():\n",
    "    metadata = []\n",
    "    \n",
    "    with gzip.open(PATH / 't10k-labels-idx1-ubyte.gz', 'rb') as fp:\n",
    "        magic, size = struct.unpack(\">II\", fp.read(8))\n",
    "        labels = np.frombuffer(fp.read(), dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "        print(magic, size)\n",
    "\n",
    "    with gzip.open(PATH / 't10k-images-idx3-ubyte.gz', 'rb') as fp:\n",
    "        magic, size = struct.unpack(\">II\", fp.read(8))\n",
    "        nrows, ncols = struct.unpack(\">II\", fp.read(8))\n",
    "        data = np.frombuffer(fp.read(), dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "        data = data.reshape((size, nrows, ncols))\n",
    "        print(magic, size, nrows, ncols)\n",
    "\n",
    "    VALID_PATH = PATH / 'valid'\n",
    "    VALID_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    for n,label in zip(range(len(data)), labels):\n",
    "        im = pi.fromarray(data[n,:,:])\n",
    "        outfilename = str(n) + '.png'\n",
    "        outfile = VALID_PATH / outfilename\n",
    "        im.save(outfile, format='png')\n",
    "        metadata.append(['valid/' + outfilename, label])\n",
    "\n",
    "    # Now Training data.\n",
    "    with gzip.open(PATH / 'train-labels-idx1-ubyte.gz', 'rb') as fp:\n",
    "        magic, size = struct.unpack(\">II\", fp.read(8))\n",
    "        labels = np.frombuffer(fp.read(), dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "        print(magic, size)\n",
    "\n",
    "    with gzip.open(PATH / 'train-images-idx3-ubyte.gz', 'r') as fp:\n",
    "        magic, size = struct.unpack(\">II\", fp.read(8))\n",
    "        nrows, ncols = struct.unpack(\">II\", fp.read(8))\n",
    "        data = np.frombuffer(fp.read(), dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "        data = data.reshape((size, nrows, ncols))\n",
    "        print(magic, size, nrows, ncols)\n",
    "        \n",
    "    TRAIN_PATH = PATH / 'train'\n",
    "    TRAIN_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    for n,label in zip(range(len(data)), labels):\n",
    "        im = pi.fromarray(data[n,:,:])\n",
    "        outfilename = str(n) + '.png'\n",
    "        outfile = TRAIN_PATH / outfilename\n",
    "        im.save(outfile, format='png')\n",
    "        metadata.append(['train/' + outfilename, label])\n",
    "\n",
    "    metadata_df = pd.DataFrame(metadata, columns=['name', 'label'])\n",
    "    metadata_df.to_csv(PATH / 'labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (PATH / 'train').exists():\n",
    "    extract_kmnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fastai_imported == True:\n",
    "    data = ImageDataBunch.from_csv(PATH)\n",
    "    data.show_batch(rows=3, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fastai_imported == True:\n",
    "    learn = cnn_learner(data, models.resnet50, metrics=accuracy)\n",
    "    if not learn.load('kmnist-stage-2-50'):\n",
    "        print('Could not load model, training instead.')\n",
    "        learn.fit(4)\n",
    "        learn.save('kmnist-stage-1-50');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/learning_rate_example.png\" alt=\"learning rate chart\" width=\"40%\" align=\"rigth\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = cnn_learner(data, models.resnet50, metrics=accuracy)\n",
    "# learn.fit(4, 3e-3)\n",
    "# learn.save('kmnist-stage-1-50');\n",
    "# learn.lr_find()\n",
    "# learn.recorder.plot()\n",
    "# learn.unfreeze()\n",
    "# learn.fit_one_cycle(4, slice(3e-5, 3e-4))\n",
    "# learn.save('kmnist-stage-2-50');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fastai_imported == True:\n",
    "    interp = ClassificationInterpretation.from_learner(learn)\n",
    "    losses,idxs = interp.top_losses()\n",
    "    len(data.valid_ds)==len(losses)==len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fastai_imported == True:\n",
    "    interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fastai_imported == True:\n",
    "    interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(PATH / 't10k-images-idx3-ubyte.gz', 'rb') as fp:\n",
    "    magic, size = struct.unpack(\">II\", fp.read(8))\n",
    "    nrows, ncols = struct.unpack(\">II\", fp.read(8))\n",
    "    data_raw = np.frombuffer(fp.read(), dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "    data_raw = data_raw.reshape((size, nrows, ncols))\n",
    "    print(magic, size, nrows, ncols)\n",
    "\n",
    "images = [pi.fromarray(data_raw[n,:,:]) for n in range(len(data_raw))]\n",
    "\n",
    "with gzip.open(PATH / 't10k-labels-idx1-ubyte.gz', 'rb') as fp:\n",
    "    magic, size = struct.unpack(\">II\", fp.read(8))\n",
    "    labels = np.frombuffer(fp.read(), dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "    print(magic, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [pi.fromarray(data_raw[n,:,:]) for n in range(len(data_raw))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for n in range(len(data_raw)):\n",
    "    b = BytesIO()\n",
    "    im = pi.fromarray(data_raw[n,:,:])\n",
    "    im.save(b, format='png')\n",
    "    images.append(b.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_widget(value=images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of relearned kanji images.\n",
    "z_container_layout = Layout(border='0px solid  grey', width='50px', length='50px', margin='0px 0px 0px 0px')\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='flex-start')\n",
    "c_container_layout = Layout(border='0px solid black', width='50%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig1 = VBox(children=[HBox(children=[VBox(children=[Image_widget(value=image, layout=z_container_layout)], layout=a_container_layout) \n",
    "                     for image in images[10*m:10*m+10]], layout=b_container_layout) for m in range(13)], layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of labels.\n",
    "hiragana = ['お', 'き', 'す', 'つ', 'な', 'は', 'ま', 'や', 'れ', 'を']\n",
    "h_labels = [hiragana[l] for l in labels]\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='space-between')\n",
    "c_container_layout = Layout(border='0px solid black', width='50%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig2 = VBox(children=[HBox(children=[HBox(children=[HTML(value=str(label))], layout=a_container_layout) \n",
    "                     for label in h_labels[no_boxes_per_line*m:no_boxes_per_line*m+no_boxes_per_line]], layout=b_container_layout) for m in range(13)],\n",
    "     layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HBox(children=[fig1, fig2], layout=Layout(border='0px solid black', justify_content='space-around'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_images = []\n",
    "for label in [0, 1, 2, 3, 4, 5, 6, 7, 8 , 9]:\n",
    "    subscripts = [n for n,l in enumerate(labels) if l == label]\n",
    "    character_images.extend([images[n] for n in subscripts[0:30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(character_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of relearned kanji images.\n",
    "z_container_layout = Layout(border='0px solid  grey', width='80px', length='80px', margin='0px 0px 0px 0px')\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='flex-start')\n",
    "c_container_layout = Layout(border='0px solid black', width='100%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig3 = VBox(children=[HBox(children=[VBox(children=[Image_widget(value=image, layout=z_container_layout)], layout=a_container_layout) \n",
    "                     for image in character_images[30*m:30*m+30]], layout=b_container_layout) for m in range(10)], layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_container_layout = Layout(border='0px solid  grey', width='80px', length='80px', margin='0px 0px 0px 0px')\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='flex-start')\n",
    "c_container_layout = Layout(border='0px solid black', width='30%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig4 = VBox(children=[HBox(children=[VBox(children=[Image_widget(value=image, layout=z_container_layout)], layout=a_container_layout) \n",
    "                     for image in character_images[10*m:10*m+10]], layout=b_container_layout) for m in range(10)], layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = BytesIO()\n",
    "im = pi.open('images/200014735/image/200014735_00014.jpg')\n",
    "im.save(b, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = (1000, 820, 5300, 2950)\n",
    "region = im.crop(box)\n",
    "imgByteArr = BytesIO()\n",
    "region.save(imgByteArr, format='PNG')\n",
    "imgByteArr = imgByteArr.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HBox(children=[fig4, VBox(children=[Image_widget(value=imgByteArr)], layout=Layout(width='60%'))], layout=Layout(border='0px solid black', justify_content='space-around'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['お', 'き', 'す', 'つ', 'な', 'は', 'ま', 'や', 'れ', 'を']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import ImageFont\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "font = ImageFont.truetype(\"/System/Library/Fonts/ヒラギノ明朝 ProN.ttc\",40)\n",
    "img=Image.new(\"RGBA\", (500,50),(255,255,255))\n",
    "draw = ImageDraw.Draw(img)\n",
    "draw.text((0, 0),\"お き す つ な は ま や れ を\",(0,0,0),font=font)\n",
    "draw = ImageDraw.Draw(img)\n",
    "# img.save(\"a_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = ImageFont.truetype(\"/System/Library/Fonts/ヒラギノ明朝 ProN.ttc\",40)\n",
    "img=Image.new(\"RGBA\", (520,50),(0,0,0))\n",
    "draw = ImageDraw.Draw(img)\n",
    "draw.text((0, 0),\"お き す つ な は ま や れ を\",(255,255,255),font=font)\n",
    "draw = ImageDraw.Draw(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = ImageFont.truetype(\"/System/Library/Fonts/ヒラギノ明朝 ProN.ttc\", 28)\n",
    "modern_images = []\n",
    "for char in ['お', 'き', 'す', 'つ', 'な', 'は', 'ま', 'や', 'れ', 'を']:\n",
    "    img=Image.new(\"L\", (28,28), 0)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.text((0, 0), char, 255, font=font)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    b = BytesIO()\n",
    "    img.save(b, format='png')\n",
    "    modern_images.append(b.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_images = []\n",
    "for label in [0, 1, 2, 3, 4, 5, 6, 7, 8 , 9]:\n",
    "    subscripts = [n for n,l in enumerate(labels) if l == label]\n",
    "    character_images.extend([images[n] for n in subscripts[0:10]])\n",
    "\n",
    "for n in range(10):\n",
    "    character_images[10*n] = modern_images[n]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_container_layout = Layout(border='0px solid  grey', width='80px', length='80px', margin='0px 0px 0px 0px')\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='flex-start')\n",
    "c_container_layout = Layout(border='0px solid black', width='33%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig5 = VBox(children=[HBox(children=[VBox(children=[Image_widget(value=image, layout=z_container_layout)], layout=a_container_layout) \n",
    "                     for image in character_images[10*m:10*m+10]], layout=b_container_layout) for m in range(10)], layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HBox(children=[fig4, fig5], layout=Layout(border='1px solid red', justify_content='space-around'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HBox(children=[fig5, VBox(children=[Image_widget(value=imgByteArr)], layout=Layout(width='66%'))], \n",
    "     layout=Layout(border='0px solid black', justify_content='space-around'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_images = []\n",
    "for label in [0, 1, 2, 3, 4, 5, 6, 7, 8 , 9]:\n",
    "    subscripts = [n for n,l in enumerate(labels) if l == label]\n",
    "    character_images.extend([images[n] for n in subscripts[0:30]])\n",
    "\n",
    "for n in range(10):\n",
    "    character_images[30*n] = modern_images[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of relearned kanji images.\n",
    "z_container_layout = Layout(border='0px solid  grey', width='80px', length='80px', margin='0px 0px 0px 0px')\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='flex-start')\n",
    "c_container_layout = Layout(border='0px solid black', width='100%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig6 = VBox(children=[HBox(children=[VBox(children=[Image_widget(value=image, layout=z_container_layout)], layout=a_container_layout) \n",
    "                     for image in character_images[30*m:30*m+30]], layout=b_container_layout) for m in range(10)], layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai-cpu]",
   "language": "python",
   "name": "conda-env-fastai-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
