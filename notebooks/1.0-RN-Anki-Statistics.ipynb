{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anki Statistics for \"Rembering the Kanji\" Flashcards\n",
    "\n",
    "<img src=\"images/vocab_relearn.png\" alt=\"Current kanji being relearned.\" width=\"48%\" align=\"left\">\n",
    "<img src=\"images/anki_stats.png\" border=\"1px\" width=\"48%\" align=\"right\">    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fundamental packages\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import sqlite3\n",
    "import json\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from tabulate import tabulate\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Charts\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Widgets to combine charts with interactive controls.\n",
    "from ipywidgets import HTML, Image, Layout, Button, Label\n",
    "from ipywidgets import HBox, VBox, Box\n",
    "\n",
    "# The image used in the flashcards are SVG graphics generated by the anki \"Kanji Colorizer\" package. \n",
    "# In order to display an array of images, need to convert svg to png.\n",
    "import cairosvg\n",
    "\n",
    "# In order to culuster the keywords, use pymagnitude to read in the english word vectors.\n",
    "import pymagnitude\n",
    "\n",
    "# Utilize the UNIHAN database for looking up information regarding characters.\n",
    "from cihai.core import Cihai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing an Anki Database\n",
    "<img src=\"images/rtk.jpg\" width=\"200\" align=\"right\" style=\"margin: 0px 20px\">\n",
    "\n",
    "[Anki flashcards](https://apps.ankiweb.net) use spaced repetition to help learn facts presented as a set of flashcards. In this instance, there is a flash card for each of the 2136 [jōyō kanji](https://en.wikipedia.org/wiki/List_of_jōyō_kanji), and the layout of the cards follow the scheme outlined in the book \"Rembering the Kanji.\" In the RTK scheme, there is a set 2136 unique keywords that correspond to each kanji and a story to help visualize each character -- the characters are ordered according to their core components in an effort to assist memorization.\n",
    "\n",
    "<img src=\"images/card_懲.png\" width=\"200\" align=\"left\" border=\"0\" style=\"margin: 0px 0px\">\n",
    "\n",
    "Anki saves data in sqlite databases with a table each for cards, notes, collections, and a review log. This flashcard deck, \"Heisig - Remembering The Kanji,\" also includes an SVG graphic for each character generated from the [KanjiVG](http://kanjivg.tagaini.net/index.html) project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"../models/collection.anki2\")\n",
    "df_cards = pd.read_sql_query(\"SELECT * from cards\", con)\n",
    "df_notes = pd.read_sql_query(\"SELECT * from notes\", con)\n",
    "df_col = pd.read_sql_query(\"SELECT * from col\", con)\n",
    "df_revlog = pd.read_sql_query(\"SELECT * from revlog\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns of data frame into lookup mapping.\n",
    "card_note_mapping = dict(df_cards[['id', 'nid']].values)\n",
    "note_fields_mapping = dict(df_notes[['id', 'flds']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This Anki flashcard deck contains 3008 cards. The first 2136 cards are the [jōyō kanji](https://en.wikipedia.org/wiki/List_of_jōyō_kanji) (from Volume 1 of Rembembering the Kanji) and an additional 872 from Volume 3 (Volume 2 of RTK focuses on strategies for memorizing the multiple pronunciations of each character).\n",
    "\n",
    "The [database structure](https://github.com/ankidroid/Anki-Android/wiki/Database-Structure) describes the fields used by Anki. These include\n",
    "* **id:** the epoch milliseconds of when the card was created\n",
    "* **nid:** notes id\n",
    "* **type:** 0=new, 1=learning, 2=due, 3=filtered\n",
    "* **due:** Due is used differently for different card types: \n",
    "     * new: note id or random int\n",
    "     * due: integer day, relative to the collection's creation time\n",
    "     * learning: integer timestamp\n",
    "* **ivl:** interval (used in SRS algorithm). Negative = seconds, positive = days\n",
    "* **reps:** number of reviews\n",
    "* **lapses:** the number of times the card went from a \"was answered correctly\" to \"was answered incorrectly\" state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_cards))\n",
    "df_cards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer to track cards. Should not be necessary.\n",
    "df_cards['index'] = list(range(len(df_cards)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Anki desktop application, export the flashcards as an Anki Deck Package (file extension apkg) and include the associated media. Also exported is a table mapping the on disk filenames of images with references used in the notes markup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ray/scratch/anki_statistics/models/heisig/media') as fp:\n",
    "    image_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Card 909 maps to RTK frame 953 (kanji 懲).\n",
    "image_data['909']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_map = {}\n",
    "for key in image_data:\n",
    "    image_file_map[image_data[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rtk(note_id):\n",
    "    '''\n",
    "    The notes table contains a column, flds, as one long string. The seven fields for the \"Heisig - Remembering The Kanji\" flashcard deck\n",
    "    are Kanji, Keyword, My Story, Stroke Count, Heisig Number, Diagram, and RTK. \n",
    "    '''\n",
    "    fields = note_fields_mapping[note_id].split('\\x1f')\n",
    "    rtk = fields[6]\n",
    "    return rtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kanji(note_id):\n",
    "    '''\n",
    "    The notes table contains a column, flds, as one long string. The seven fields for the \"Heisig - Remembering The Kanji\" flashcard deck\n",
    "    are Kanji, Keyword, My Story, Stroke Count, Heisig Number, Diagram, and RTK. \n",
    "    '''\n",
    "    fields = note_fields_mapping[note_id].split('\\x1f')\n",
    "    kanji = fields[0]\n",
    "    return kanji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyword(note_id):\n",
    "    '''\n",
    "    The notes table contains a column, flds, as one long string. The seven fields for the \"Heisig - Remembering The Kanji\" flashcard deck\n",
    "    are Kanji, Keyword, My Story, Stroke Count, Heisig Number, Diagram, and RTK. \n",
    "    '''\n",
    "    fields = note_fields_mapping[note_id].split('\\x1f')\n",
    "    keyword = fields[1]\n",
    "    return keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagram_filename(note_id):\n",
    "    '''\n",
    "    The notes table contains a column, flds, as one long string. The seven fields for the \"Heisig - Remembering The Kanji\" flashcard deck\n",
    "    are Kanji, Keyword, My Story, Stroke Count, Heisig Number, Diagram, and RTK. \n",
    "    '''\n",
    "    fields = note_fields_mapping[note_id].split('\\x1f')\n",
    "    try:\n",
    "        image_name = fields[5].split('=')[1].split('>')[0].replace('\"','')\n",
    "    except Exception as ex:\n",
    "        print(fields, ex)\n",
    "        return None\n",
    "    \n",
    "    # Hack to deal with a few malformed image file names.\n",
    "    if ' /' in image_name:\n",
    "        image_name = image_name.replace(' /','')\n",
    "    \n",
    "    return image_file_map[image_name]\n",
    "\n",
    "def get_diagram(note_id):\n",
    "    file_name = get_diagram_filename(note_id)\n",
    "    with open(\"/Users/ray/scratch/anki_statistics/models/heisig/\" + file_name, \"rb\") as fp:\n",
    "        image = fp.read()\n",
    "        png = cairosvg.svg2png(image, dpi=100)\n",
    "        \n",
    "    return png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns to the cards table in order to track the RTK frame number, kanji, and keyword from the textbook.\n",
    "df_cards['rtk'] = df_cards.nid.map(get_rtk)\n",
    "df_cards['kanji'] = df_cards.nid.map(get_kanji)\n",
    "df_cards['keyword'] = df_cards.nid.map(get_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lapses = max(df_cards.lapses)\n",
    "mask = (df_cards.lapses == max_lapses)\n",
    "df_cards[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KanjiVG -- Generate colorized SVG diagrams for Kanji characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.external.kanjicolorizer.colorizer import (KanjiVG, KanjiColorizer, InvalidCharacterError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nid = df_cards[df_cards.kanji == '懲'].nid.values[0]\n",
    "get_diagram_filename(nid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '懲'\n",
    "characters_to_colorize = [c for c in s if ord(c) >= 19968 and ord(c) <= 40879]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KanjiVG('懲').ascii_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration parameters used by Anki kanjicolorizer addon:\n",
    "\n",
    "    {\n",
    "        \"group-mode\": true,\n",
    "        \"image-size\": 327,\n",
    "        \"mode\": \"spectrum\",\n",
    "        \"saturation\": 0.95,\n",
    "        \"value\": 0.75\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"--mode \"\n",
    "config += \"spectrum \"\n",
    "config += \" --group-mode \"\n",
    "config += \" --saturation \"\n",
    "config += \"0.95 \"\n",
    "config += \" --value \"\n",
    "config += \"0.75 \"\n",
    "config += \" --image-size \"\n",
    "config += \"327 \"\n",
    "kc = KanjiColorizer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_svg = kc.get_colored_svg('懲').encode('utf_8')\n",
    "png = cairosvg.svg2png(char_svg)\n",
    "display(Image(value=png, layout=Layout(width='100px', length='100px')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_cards[df_cards.kanji == '懲'])\n",
    "nid = df_cards[df_cards.kanji == '懲'].nid.values[0]\n",
    "print(get_diagram_filename(nid))\n",
    "with open(\"/Users/ray/scratch/anki_statistics/models/heisig/909\", \"rb\") as fp:\n",
    "    image = fp.read()\n",
    "    png = cairosvg.svg2png(image)\n",
    "    display(Image(value=png, layout=Layout(width='100px', length='100px')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image_widget variable displays the current character when hovered over with the cursor.\n",
    "nid = df_cards[df_cards.kanji == '懲'].nid.values[0]\n",
    "png = get_diagram(nid)\n",
    "image_widget = Image(value=png, layout=Layout(width='100px', length='100px'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnose mismatch in sum of reps vs. total reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reps = df_cards.reps.sum()\n",
    "total_reviews = len(df_revlog)\n",
    "print(total_reps, total_reviews)\n",
    "\n",
    "# The sum of the reps recorded in df_cards doesn't match what the anki statistics ui reports. \n",
    "# Checking that there are no reps recorded on cards that do not have a Rembering The Kanji index (i.e. not i first book).\n",
    "mask = (df_cards.rtk == '') & (df_cards.reps > 0)\n",
    "df_cards[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Card deck has 3008 total cards (volumes 1 & 3 of RTK). In the card deck (as of 11 June 2019), only the volume 1 cards have the tag RTK.\n",
    "# Going to clobber the cards that do not have an RTK tag.\n",
    "print(len(df_cards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames = df_cards[ df_cards.rtk == '' ].index\n",
    "df_cards.drop(indexNames , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_cards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chart to Display Review Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hover_fn(trace, points, state):\n",
    "    '''\n",
    "    For scatter plots, hovering over a point gives data about the character repetitions and displays the KanjiVG diagram\n",
    "    that is colored by the subcomponents. Must be converted to png in order to display a (grid) of images.\n",
    "    \n",
    "    Does not return a value, but updates the image_widget and details variables as side effects.\n",
    "    '''\n",
    "    ind = points.point_inds[0]\n",
    "    hd = dict(df_cards[['id', 'nid', 'reps', 'index']].iloc[ind])\n",
    "    fields = note_fields_mapping[hd['nid']].split('\\x1f')\n",
    "    kanji = fields[0]\n",
    "    keyword = fields[1]\n",
    "    rtk = fields[6]\n",
    "    image_name = fields[5].split('=')[1].split('>')[0].replace('\"','')\n",
    "    file_name = image_file_map[image_name]\n",
    "    with open(\"/Users/ray/scratch/anki_statistics/models/heisig/\" + file_name, \"rb\") as fp:\n",
    "        image = fp.read()\n",
    "        png = cairosvg.svg2png(image, dpi=300)\n",
    "    image_widget.value = png\n",
    "#     details.value = df_cards[['id', 'nid', 'reps', 'index']].iloc[ind].to_frame().to_html()\n",
    "    details.value = ''' <table border=\"0\" align=\"left\">\n",
    "                        <tr><td>{} {}</td></tr>\n",
    "                        <tr><td>RTK: {}</td></tr>\n",
    "                        <tr><td>REPS: {}</td></tr>\n",
    "                        <tr><td>nid: {}</td></tr>\n",
    "                        </table>\n",
    "                        '''.format(kanji, keyword, rtk, hd['reps'], hd['nid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to hold the display of charts generated below.\n",
    "details_kodansha = HBox(children=[HTML(value='Kodansha place holder.</b>')])\n",
    "details_nearest_neighbors = HBox(children=[HTML(value='Keyword nearest neighbors place holder.</b>')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduce the standard Anki Statistics bar chart counting the number of reviews per card. \n",
    "\n",
    "cards_fig = go.FigureWidget(\n",
    "    data=[\n",
    "        dict(\n",
    "            type='scatter',\n",
    "            x = df_cards['rtk'],\n",
    "            y = df_cards['reps'],\n",
    "            mode = 'markers'\n",
    "        )\n",
    "    ])\n",
    "\n",
    "scatter = cards_fig.data[0]\n",
    "scatter.hoverinfo = 'text'\n",
    "# scatter.on_hover(hover_fn)\n",
    "scatter.marker.opacity = 0.4\n",
    "scatter.marker.size = 4\n",
    "scatter.marker.color = None\n",
    "cards_fig.layout.template = 'seaborn'\n",
    "margin=go.layout.Margin(\n",
    "        l=20,\n",
    "        r=10,\n",
    "        b=10,\n",
    "        t=0,\n",
    "        pad=4\n",
    ")\n",
    "cards_fig.layout.margin = margin\n",
    "cards_fig.layout.xaxis.title = 'Rembering the Kanji Index'\n",
    "cards_fig.layout.yaxis.title = 'Repetitions'\n",
    "cards_fig.layout.hovermode = 'closest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Compute and display Jacard similarity of each Kodansha cluster with nearest neighbor list (or hdbscan cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy figure, real one will be updated in cell below.\n",
    "fig1 = go.FigureWidget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_layout = Layout(border='1px solid grey', width='100%')\n",
    "vcontainer_layout = Layout(border='0px solid black', justify_content='space-between')\n",
    "rcontainer_layout = Layout(border='0px solid red')\n",
    "gcontainer_layout = Layout(border='0px solid green', width='400px')\n",
    "HBox(children=[VBox(children=[cards_fig], layout=gcontainer_layout), \n",
    "               VBox(children=[VBox(children=[details_kodansha, details_nearest_neighbors],layout=rcontainer_layout)], \n",
    "                    layout=vcontainer_layout),# HBox(children=[fig1], layout=Layout(width='30%')),\n",
    "               VBox(children=[image_widget], layout=rcontainer_layout)\n",
    "              ], \n",
    "     layout=container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information from cards to the review log table.\n",
    "df_revlog['nid'] = df_revlog.cid.map(card_note_mapping)\n",
    "df_revlog['flds'] = df_revlog.nid.map(note_fields_mapping)\n",
    "df_revlog['formatted_flds'] = df_revlog['flds'].str.split('\\x1f')\n",
    "df_revlog['kanji'] = df_revlog['formatted_flds'].map(lambda x: x[0])\n",
    "df_revlog['keyword'] = df_revlog['formatted_flds'].map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the review log dataframe for localtime in Hawaii. Does not take into acccount\n",
    "# the fact that review sessions started every morning at 4am in Hawaii. Traveled two times\n",
    "# to EST during the project which made it difficult to continue the reviews on time.\n",
    "dti = pd.to_datetime(list(df_revlog['id']/1000.0), unit='s')\n",
    "dti = dti.tz_localize('UTC')\n",
    "dti = dti.tz_convert('US/Hawaii')\n",
    "df_revlog = df_revlog.set_index(dti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_type(row):\n",
    "    rev_type = ''\n",
    "    if row['type'] == 0:\n",
    "        rev_type = 'learn'\n",
    "    elif (row['type'] == 1) & (row['ivl'] > 21):\n",
    "        rev_type = 'mature'\n",
    "    elif (row['type'] == 1) & (row['ivl'] <= 21):\n",
    "        rev_type = 'young'\n",
    "    elif row['type'] == 2:\n",
    "        rev_type = 'relearn'\n",
    "    else:\n",
    "        print('error {}'.format(row))\n",
    "    \n",
    "    return rev_type\n",
    "\n",
    "df_revlog['review_type'] = df_revlog.apply(review_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_review_type(kanji):\n",
    "    mask = (df_revlog.kanji == kanji)\n",
    "    return df_revlog[mask].iloc[-1]['review_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cards['review_type'] = df_cards.kanji.map(get_current_review_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the scatter plot of RTK card number vs review count to highlight the current review type.\n",
    "anki_colors = {'mature':'green', 'young':'lightgreen', 'learn':'blue', 'relearn':'red'}\n",
    "\n",
    "scatter.marker.color = df_cards.review_type.map(anki_colors)\n",
    "scatter.marker.opacity = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Chart reproducing Anki Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cards.groupby('review_type').count().loc[:,'id'].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Add python callback to update stacked bars with total reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_data = []\n",
    "\n",
    "groupby = df_revlog.groupby('review_type')\n",
    "for review_type in ['mature', 'young', 'learn', 'relearn']:\n",
    "    group = groupby.get_group(review_type)\n",
    "    # Review periods start at 4am (HST) every morning, so use a base of 4 and frequency of 24*n hours.\n",
    "    card_series = group.loc[:, 'cid'].groupby(pd.Grouper(freq='24H', base=4, label='left')).count()\n",
    "    card_data.append(go.Bar(x=card_series.index, y=card_series.values,\n",
    "                            name=review_type, marker=dict(color=anki_colors[review_type]), opacity=0.9))\n",
    "    \n",
    "card_series = df_revlog.loc[:, 'cid'].groupby(pd.Grouper(freq='24H', base=4, label='left')).count()\n",
    "card_data.append(go.Bar(x=card_series.index, y=card_series.values,\n",
    "                            name='total', marker=dict(color='white'), opacity=0.1))\n",
    "\n",
    "layout = go.Layout(title='Review Count', xaxis=dict(title='Date'), barmode='stack', yaxis=dict(title='Count'))\n",
    "fig = go.FigureWidget(data=card_data, layout=layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Current Keywords/Kanji being Relearned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all rendered SVG images of kanji diagrams that are being relearned.\n",
    "mask = (df_cards.review_type == 'relearn')\n",
    "images = list(df_cards[mask].nid.map(get_diagram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of relearned kanji images.\n",
    "z_container_layout = Layout(border='0px solid  grey', width='50px', length='50px')\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='flex-start')\n",
    "c_container_layout = Layout(border='0px solid black', width='50%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig1 = VBox(children=[HBox(children=[VBox(children=[Image(value=image, layout=z_container_layout)], layout=a_container_layout) \n",
    "                     for image in images[10*m:10*m+10]], layout=b_container_layout) for m in range(13)], layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of relearned keywords.\n",
    "keywords = list(df_cards[mask].keyword)\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='space-between')\n",
    "c_container_layout = Layout(border='0px solid black', width='50%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig2 = VBox(children=[HBox(children=[HBox(children=[HTML(value=keyword)], layout=a_container_layout) \n",
    "                     for keyword in keywords[no_boxes_per_line*m:no_boxes_per_line*m+no_boxes_per_line]], layout=b_container_layout) for m in range(13)],\n",
    "     layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(keywords))\n",
    "HBox(children=[fig1, fig2], layout=Layout(border='0px solid black', justify_content='space-around'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters of English keywords associated with kanji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english_model =  '../models/crawl-300d-2M.magnitude'\n",
    "english_model =  '/Users/ray/scratch/flash/models/wiki-news-300d-1M.magnitude'\n",
    "english_vectors = pymagnitude.Magnitude(english_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cihai Utility for UNIHAN character data\n",
    "<img src=\"images/cihai.jpg\" width=\"400\" align=\"right\" style=\"margin: 0px 20px\">\n",
    "\n",
    "The [Cihai](https://cihai.git-pull.com/en/latest/features.html) project provides a (sqlalchemy) interface to [UNIHAN](https://unicode.org/charts/unihan.html) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full config for Cihai (via sqlalchemy) to supress error. Includes the argument \"?check_same_thread=False\" in database url.\n",
    "# \"SQLite objects created in a thread can only be used in that same thread.\"\n",
    "base_directory = '../'\n",
    "cihai_path = base_directory + '/models/cihai.db'\n",
    "config = {'debug': False,\n",
    "  'database': {'url': 'sqlite:///' + cihai_path + '?check_same_thread=False'},\n",
    "  'dirs': {'cache': base_directory,\n",
    "  'log': base_directory,\n",
    "  'data': base_directory}}\n",
    "\n",
    "cihai = Cihai(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_Unihan(character):\n",
    "    # TODO: Documentation for UNIHAN (CiHai package).\n",
    "    kGlyphs = {}\n",
    "    try:\n",
    "        query = cihai.lookup_char(character)\n",
    "        glyph = query.first()\n",
    "        kGlyphs = {\n",
    "            'kMandarin': glyph.kMandarin,\n",
    "            'kCantonese': glyph.kCantonese,\n",
    "            'kTang': glyph.kTang,\n",
    "            'kJapaneseOn': glyph.kJapaneseOn,\n",
    "            'kJapaneseKun': glyph.kJapaneseKun,\n",
    "            'kKorean': glyph.kKorean,\n",
    "            'kHangul': glyph.kHangul,\n",
    "            'kDefinition': glyph.kDefinition\n",
    "        }\n",
    "    except Exception as ex:\n",
    "        print('Exception: {}, Character {}'.format(ex, character))\n",
    "    return kGlyphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unihan_data = {char:lookup_Unihan(char) for char in list(df_cards.kanji)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbors\n",
    "\n",
    "Very slow, so cache a version on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = 100\n",
    "cached_knn = '../data/processed/knn_data.json'\n",
    "if not os.path.isfile(cached_knn):\n",
    "    knn_data = {keyword:{k:sim for k, sim in english_vectors.most_similar_approx(keyword, topn=topn)} for keyword in list(df_cards.keyword)}\n",
    "    with open(cached_knn, 'w') as fp:\n",
    "        json.dump(knn_data, fp)\n",
    "\n",
    "with open(cached_knn) as fp:\n",
    "    knn_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_kanji_mapping = dict(df_revlog[['keyword', 'kanji']].values)\n",
    "kanji_keyword_mapping = dict(df_revlog[['kanji', 'keyword']].values)\n",
    "\n",
    "def keyword_neighbors(keyword='inspection'):\n",
    "    topn = 100\n",
    "#     nearest_keywords_sims = {keyword:sim for keyword, sim in english_vectors.most_similar_approx(keyword, topn=topn)}\n",
    "    nearest_keywords_sims = knn_data[keyword]\n",
    "    nearest_keywords_sims[keyword] = 1.0\n",
    "    nearest_keywords = {k for k in nearest_keywords_sims}\n",
    "    nearest_keywords = nearest_keywords.intersection(set(keywords))\n",
    "    nearest_keywords.add(keyword)\n",
    "\n",
    "    keyword_data = []\n",
    "    cols = ['keyword', 'kanji', 'similarity']\n",
    "    glyph_data = unihan_data['請']\n",
    "    cols.extend(list(glyph_data.keys()))\n",
    "    \n",
    "    for k in nearest_keywords:\n",
    "        glyph_data = {}\n",
    "        kanji = keyword_kanji_mapping[k]\n",
    "        glyph_data['keyword'] = k\n",
    "        glyph_data['kanji'] = kanji\n",
    "        glyph_data['similarity'] = nearest_keywords_sims[k]\n",
    "        glyph_data.update(unihan_data[kanji])\n",
    "        keyword_data.append(glyph_data)\n",
    "        \n",
    "    df = pd.DataFrame(keyword_data, columns=cols)\n",
    "    df = df.sort_values(by='similarity', ascending=False)\n",
    "    df = df.round({'similarity': 2})\n",
    "#     print(tabulate(df, showindex='never'))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_neighbors(keyword='inspection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hnn(ind):\n",
    "#     ind = points.point_inds[0]\n",
    "    hd = dict(df_cards[['id', 'nid', 'reps', 'index']].iloc[ind])\n",
    "    fields = note_fields_mapping[hd['nid']].split('\\x1f')\n",
    "    kanji = fields[0]\n",
    "    keyword = fields[1]\n",
    "    df = keyword_neighbors(keyword='inspection')\n",
    "    table = tabulate(df[['keyword', 'kanji', 'similarity', 'kJapaneseOn']], tablefmt='html', headers=df.columns, showindex='never')\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(hnn(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hover_fn_nn(trace, points, state):\n",
    "    '''\n",
    "    The notes table contains a column, flds, as one long string. The seven fields for the \"Heisig - Remembering The Kanji\" flashcard deck\n",
    "    are Kanji, Keyword, My Story, Stroke Count, Heisig Number, Diagram, and RTK. \n",
    "    '''\n",
    "    ind = points.point_inds[0]\n",
    "    hd = dict(df_cards[['id', 'nid', 'reps', 'index']].iloc[ind])\n",
    "    fields = note_fields_mapping[hd['nid']].split('\\x1f')\n",
    "    kanji = fields[0]\n",
    "    keyword = fields[1]\n",
    "    df = keyword_neighbors(keyword=keyword)\n",
    "#     details.value = keyword\n",
    "    table = tabulate(df[['keyword', 'kanji', 'similarity', 'kJapaneseOn']], tablefmt='html', headers=df.columns, showindex='never')\n",
    "    details_nearest_neighbors.children = [HTML(table)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter.hoverinfo = 'text'\n",
    "scatter.on_hover(hover_fn_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse word clusters (scraped from) Kodansha's dictionary.\n",
    "<img src=\"images/kodansha_cover.jpg\" width=\"200\" align=\"left\" style=\"margin: 0px 20px\">\n",
    "\n",
    ">    **Kanji Synonyms** The words of a language form a closely linked network of interdependent\n",
    ">    units. The meaning of a word or expression cannot really be understood unless its relationships with\n",
    ">    other closely related words are taken into account. In English, for example, such words as kill, murder,\n",
    ">    and execute share the meaning of ‘put to death’, but they differ considerably in usage and connotation.\n",
    ">    The ability to distinguish between such words not only allows one to gain a fuller understanding of\n",
    ">    their individual shades of meaning, but also helps one write with greater clarity and precision.\n",
    ">\n",
    ">    A special feature of this dictionary, presented for the first time in the first edition, is the complete guidance\n",
    ">    it offers for the precise distinctions between kanji synonyms, or characters of similar meaning. Since\n",
    ">    a proper understanding of the meanings of each character is essential for the effective mastery of the\n",
    ">    Japanese vocabulary, this will be of considerable benefit to the serious student. The kanji synonyms serve\n",
    ">    as a powerful learning aid for the following reasons:\n",
    ">      1. They show the differences and similarities between closely related characters.\n",
    ">      2. They act as a network of cross-references for quickly locating any synonym group member.\n",
    ">      3. They act as a simple kanji thesaurus.\n",
    ">      4. They provide the educator with a valuable source of reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_CLUSTER = False\n",
    "clusters = {}\n",
    "current_cluster_id = ''\n",
    "for line in open('../data/raw/Kodansha Word Clusters.txt'):\n",
    "    if line == '\\n':\n",
    "        IN_CLUSTER = False\n",
    "        continue\n",
    "        \n",
    "    k_map = re.findall('[→]', line)\n",
    "    if k_map:\n",
    "#         print(line.strip())\n",
    "        continue\n",
    "    k_title = re.findall('([….,\\(\\)\\[\\]/\\-0-9a-zA-Z\\s]+\\n)', line)\n",
    "    try:\n",
    "        if k_title[0] == line:\n",
    "            IN_CLUSTER = True\n",
    "            clusters[line.strip()] = []\n",
    "            current_cluster_id = line.strip()\n",
    "    #             print(k_title)\n",
    "            continue\n",
    "    except Exception as ex:\n",
    "        print(line, ex)\n",
    "    k_line = re.findall('([一-龯ぁ-んァ-ン𠮟媾󠄁\\-嚮󠄃〇]+) ([….,’ \\(\\)\\[\\]/\\-0-9a-zA-Zō\\s]*) ([0-9]+)', line)\n",
    "    try:\n",
    "        num = k_line[0][2].strip()\n",
    "        if IN_CLUSTER == True:\n",
    "            clusters[current_cluster_id].append(k_line[0])\n",
    "        if num == '':\n",
    "            print(k_line)\n",
    "    except Exception as ex:\n",
    "        print(k_title, ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(clusters['rice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_cluster_rtk(cluster):\n",
    "    table_rtk = []\n",
    "    for row in cluster:\n",
    "        if row[0] in kanji_keyword_mapping:\n",
    "            row = (row[0], kanji_keyword_mapping[row[0]], row[1], row[2])\n",
    "        else:\n",
    "            row = (row[0], '', row[1], row[2])\n",
    "        table_rtk.append(row)\n",
    "    return table_rtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<style>{}</style>'.format(open('custom.css').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = '気'\n",
    "boxes = []\n",
    "boxes_layout = Layout(border='0px solid  grey', width='100%', justify_content='space-around')\n",
    "max_rows = 0\n",
    "for key in clusters:\n",
    "    if char in [t[0] for t in clusters[key]]:\n",
    "        table_rtk = extend_cluster_rtk(clusters[key])\n",
    "        if len(table_rtk) > max_rows:\n",
    "            max_rows = len(table_rtk)\n",
    "        table = tabulate(table_rtk, tablefmt='html')\n",
    "        caption = '<caption>{}</caption'.format(key)\n",
    "        table = table.replace('<table>', '<table id=\"kodansha\">\\n'+caption)\n",
    "        table = table.replace('style=\"text-align: right;\"', '')\n",
    "        boxes.append((len(table_rtk), table))\n",
    "        \n",
    "boxes_extended = []\n",
    "for no_rows, table in boxes:\n",
    "#     print(max_rows - no_rows)\n",
    "    extra_rows = '</tbody>\\n' + ('<tr>' + '<td>&nbsp;</td>'*4 + '</tr>\\n')*(max_rows - no_rows)\n",
    "    table = table.replace('</tbody>', extra_rows)\n",
    "    boxes_extended.append(table)\n",
    "    \n",
    "boxes = [HTML(box) for box in boxes_extended]\n",
    "HBox(children=boxes, layout=boxes_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_layout = Layout(height='100px', min_width='40px')\n",
    "items = [Button(layout=item_layout, description=str(i), button_style='warning') for i in range(40)]\n",
    "box_layout = Layout(overflow_x='scroll',\n",
    "                    border='3px solid black',\n",
    "                    width='500px',\n",
    "                    height='',\n",
    "                    flex_flow='row',\n",
    "                    display='flex')\n",
    "carousel = Box(children=items, layout=box_layout)\n",
    "VBox([Label('Scroll horizontally:'), carousel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = '気'\n",
    "boxes = []\n",
    "# boxes_layout = Layout(border='0px solid  grey', width='100%', justify_content='space-around')\n",
    "max_rows = 0\n",
    "for key in clusters:\n",
    "    if char in [t[0] for t in clusters[key]]:\n",
    "        table_rtk = extend_cluster_rtk(clusters[key])\n",
    "        if len(table_rtk) > max_rows:\n",
    "            max_rows = len(table_rtk)\n",
    "        table = tabulate(table_rtk, tablefmt='html')\n",
    "        caption = '<caption>{}</caption'.format(key)\n",
    "        table = table.replace('<table>', '<table id=\"kodansha\">\\n'+caption)\n",
    "        table = table.replace('style=\"text-align: right;\"', '')\n",
    "        boxes.append((len(table_rtk), table))\n",
    "        \n",
    "boxes_extended = []\n",
    "for no_rows, table in boxes:\n",
    "#     print(max_rows - no_rows)\n",
    "    extra_rows = '</tbody>\\n' + ('<tr>' + '<td>&nbsp;</td>'*4 + '</tr>\\n')*(max_rows - no_rows)\n",
    "    table = table.replace('</tbody>', extra_rows)\n",
    "    boxes_extended.append(table)\n",
    "    \n",
    "item_layout = Layout(min_width='300px')\n",
    "boxes = [HTML(box, layout=item_layout) for box in boxes_extended]\n",
    "# HBox(children=boxes, layout=boxes_layout)\n",
    "box_layout = Layout(overflow_x='scroll',\n",
    "                    border='0px solid black',\n",
    "                    width='500px',\n",
    "                    height='300px',\n",
    "                    flex_flow='row',\n",
    "                    display='flex')\n",
    "details_kodansha = Box(children=boxes, layout=box_layout)\n",
    "label = Label('Scroll horizontally:')\n",
    "details = VBox([carousel, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '</tbody>\\n' + ('<tr>' + '<td></td>'*4 + '</tr>\\n')*4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cluster_length = 0\n",
    "for key in clusters:\n",
    "    if len(clusters[key]) > max_cluster_length:\n",
    "        max_cluster_length = len(clusters[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hover_kodansha_clusters(trace, points, state):\n",
    "    ind = points.point_inds[0]\n",
    "    hd = dict(df_cards[['id', 'nid', 'reps', 'index']].iloc[ind])\n",
    "    fields = note_fields_mapping[hd['nid']].split('\\x1f')\n",
    "    kanji = fields[0]\n",
    "    keyword = fields[1]\n",
    "    image_name = fields[5].split('=')[1].split('>')[0].replace('\"','')\n",
    "    file_name = image_file_map[image_name]\n",
    "    with open(\"/Users/ray/scratch/anki_statistics/models/heisig/\" + file_name, \"rb\") as fp:\n",
    "        image = fp.read()\n",
    "        png = cairosvg.svg2png(image, dpi=300)\n",
    "    image_widget.value = png\n",
    "    boxes = []\n",
    "    boxes_layout = Layout(border='1px solid  grey', width='100%', justify_content='space-around')\n",
    "    max_rows = 0\n",
    "    cluster_names = []\n",
    "    for key in clusters:\n",
    "        if kanji in [t[0] for t in clusters[key]]:\n",
    "            cluster_names.append(key)\n",
    "            table_rtk = extend_cluster_rtk(clusters[key])\n",
    "            if len(table_rtk) > max_rows:\n",
    "                max_rows = len(table_rtk)\n",
    "            table = tabulate(table_rtk, tablefmt='html')\n",
    "            caption = '<caption>{}</caption'.format(key)\n",
    "            table = table.replace('<table>', '<table id=\"kodansha\">\\n'+caption)\n",
    "            table = table.replace('style=\"text-align: right;\"', '')\n",
    "            boxes.append((len(table_rtk), table))\n",
    "\n",
    "    boxes_extended = []\n",
    "    for no_rows, table in boxes:\n",
    "        print(max_rows - no_rows)\n",
    "        extra_rows = '</tbody>\\n' + ('<tr>' + '<td>&nbsp;</td>'*4 + '</tr>\\n')*(max_cluster_length - no_rows)\n",
    "        table = table.replace('</tbody>', extra_rows)\n",
    "        boxes_extended.append(table)\n",
    "\n",
    "    item_layout = Layout(min_width='300px')\n",
    "    boxes = [HTML(box, layout=item_layout) for box in boxes_extended]\n",
    "#     details.layout = boxes_layout\n",
    "    details_kodansha.children = boxes\n",
    "    if len(cluster_names) == 1:\n",
    "        label.value = 'Word Cluster: ' + ', '.join(cluster_names)\n",
    "    else:\n",
    "        label.value = 'Word Clusters: ' + ', '.join(cluster_names)\n",
    "    cards_fig.layout.xaxis.title.text = '{} {}'.format(kanji, keyword)\n",
    "    df = keyword_neighbors(keyword=keyword)\n",
    "#     details.value = keyword\n",
    "    table = tabulate(df[['keyword', 'kanji', 'similarity', 'kJapaneseOn']], tablefmt='html', headers=df.columns, showindex='never')\n",
    "    details_nearest_neighbors.children = [HTML(table)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter.hoverinfo = 'text'\n",
    "scatter.on_hover(hover_kodansha_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on timestamps\n",
    "\n",
    "Review periods start at 4am (HST) every morning, and the index of the review log is a UTC timestamp. Need to bucket reviews into the period between 4am of one day and the next. Many of the card reviews during the Holidays of 2018 were finished after 3am (study pattern was new cards in the morning and reviews in the evening).\n",
    "\n",
    "Three ways to work with timestamps: pandas, sqlite, and python datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamps of card reviews as computed in anki source code (routine _logLrn in sched.py).\n",
    "# This is the current \"time in seconds since the epoch as a floating point number\" UTC.\n",
    "print( int(time.time()*1000) )\n",
    "\n",
    "# For comparision, compute same time stamp using sqlite.\n",
    "cmd = \"SELECT strftime('%s', 'now') as time_stamp\"\n",
    "df = pd.read_sql_query(cmd, con)\n",
    "print(pd.to_datetime(df['time_stamp'], unit='s'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our epoch. Unix epoch is January 1, 1970, 00:00:00 (UTC).\n",
    "time.gmtime(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local time according to python\n",
    "t = time.localtime()\n",
    "print(t, t.tm_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar import TextCalendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TextCalendar(firstweekday=6)\n",
    "print(tc.formatmonth(t.tm_year, t.tm_mon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sqlite to get timestamp (10 digit) for 4am tomorrow morning.\n",
    "cmd = \"SELECT strftime('%s', 'now', 'localtime', 'start of day', '+1 day', '+4 hours') as time_stamp\"\n",
    "df = pd.read_sql_query(cmd, con)\n",
    "print(pd.to_datetime(df['time_stamp'], unit='s'))\n",
    "tomorrow_4am_localtime = int(df.iloc[0]['time_stamp'])\n",
    "print('Timestamp for tomorrow (localtime) at 4am, {}, is {} digits long.'.format(tomorrow_4am_localtime, len(str(tomorrow_4am_localtime))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between midnight 10 June 2019 and 4am 11 June.\n",
    "# Six hours -- that is HST is 10 hours behind UTC less the 4 hours to 4am.\n",
    "june_10_2019_midnight_utc = 1560247200    # int(time.time()*1000) ran at midnight 10 June 2019 in HST.\n",
    "june_11_2019_4am_hst = 1560225600         # Computed by SELECT strftime('%s','now','localtime','start of day','+1 day','+4 hours') as time_stamp\n",
    "                                          # early in the day of 10 June 2019 (before midnight UTC).\n",
    "(june_10_2019_midnight_utc - june_11_2019_4am_hst)*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# From the python datetime documentation:\n",
    "# \"Return the local date corresponding to the POSIX timestamp, such as is returned by time.time().\"\n",
    "datetime.fromtimestamp(tomorrow_4am_localtime, timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ten digit time stamp is in seconds while 13 digit time stamp is ms -- example uses pandas to convert.\n",
    "first_review = df_revlog.iloc[0]['id']\n",
    "last_review = df_revlog.iloc[-1]['id']\n",
    "print('First review: {}. Time stamp is {}, a {} digit number.'.format(pd.to_datetime(first_review, unit='ms'), first_review, len(str(first_review))))\n",
    "print('Last review: {}. Time stamp is {}, a {} digit number.'.format(pd.to_datetime(last_review, unit='ms'), last_review, len(str(last_review))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.fromtimestamp(first_review/1000.0))\n",
    "print(datetime.fromtimestamp(last_review/1000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas data structure for time stamps (date object), initialized here by a time string.\n",
    "# Example here shows 4am in the morning in the HST timezone.\n",
    "s = pd.Timestamp('2019-05-09 04:00:00-10:00')\n",
    "print('Timestamp = {}, clock in Greenwitch is {}.'.format(s.timestamp(), datetime.fromtimestamp(s.timestamp())))\n",
    "print('Timestamp = {}, local clock is {}'.format(s.timestamp(), datetime.fromtimestamp(s.timestamp(), timezone(timedelta(hours=10)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second major pandas datastructure is for time periods. \n",
    "pd.Period('2019-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_period(freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One day is 60*60*24 == 86400 seconds.\n",
    "1560225600 - 1560139200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_revlog.groupby(['review_type', pd.Grouper(key='shift_date', freq='13D')])['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bucket in df_revlog_type['learn'].groupby(pd.Grouper(freq='24H', base=4, label='right')):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cards.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(1536562919907, unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _daysSinceCreation(crt=1533996000):\n",
    "        startDate = datetime.fromtimestamp(crt)\n",
    "        startDate = startDate.replace(hour=4,\n",
    "                                      minute=0, second=0, microsecond=0)\n",
    "        return int((time.time() - time.mktime(startDate.timetuple())) // 86400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = _daysSinceCreation(1533996000)\n",
    "print(start/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def due(date):\n",
    "    return date - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_cards.due - start) == 0\n",
    "df_cards[mask].head()\n",
    "images = list(df_cards[mask].nid.map(get_diagram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in set(df_cards[mask].kanji):\n",
    "    print(c, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_container_layout = Layout(border='0px solid  grey', width='50px', length='50px')\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='flex-start')\n",
    "c_container_layout = Layout(border='0px solid black', width='50%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig1 = VBox(children=[HBox(children=[VBox(children=[Image(value=image, layout=z_container_layout)], layout=a_container_layout) \n",
    "                     for image in images[10*m:10*m+10]], layout=b_container_layout) for m in range(15)], layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = list(df_cards[mask].keyword)\n",
    "a_container_layout = Layout(border='0px solid red')\n",
    "b_container_layout = Layout(border='0px solid green', justify_content='space-between')\n",
    "c_container_layout = Layout(border='0px solid black', width='50%', flex_direction='column', justify_content='space-around')\n",
    "no_boxes_per_line = 10\n",
    "fig2 = VBox(children=[HBox(children=[HBox(children=[HTML(value=keyword)], layout=a_container_layout) \n",
    "                     for keyword in keywords[no_boxes_per_line*m:no_boxes_per_line*m+no_boxes_per_line]], layout=b_container_layout) for m in range(9)],\n",
    "     layout=c_container_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(keywords))\n",
    "HBox(children=[fig1, fig2], layout=Layout(border='0px solid black', justify_content='space-around'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.fromtimestamp(1533996000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_revlog.nid == 1185996957436)\n",
    "df_revlog[mask].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = df_revlog.iloc[0].id\n",
    "start_dt = datetime.datetime.fromtimestamp(start/1000)\n",
    "\n",
    "end = df_revlog.iloc[-1].id\n",
    "end_dt = datetime.datetime.fromtimestamp(end/1000)\n",
    "\n",
    "delta = end_dt - start_dt + datetime.timedelta(1)\n",
    "dates_in_year = [start_dt + datetime.timedelta(i) for i in range(delta.days+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays_in_year = [i.weekday() for i in dates_in_year] #gives [0,1,2,3,4,5,6,0,1,2,3,4,5,6,…] (ticktext in xaxis dict translates this to weekdays\n",
    "weeknumber_of_dates = [i.strftime(\"%Gww%V\")[2:] for i in dates_in_year] #gives [1,1,1,1,1,1,1,2,2,2,2,2,2,2,…] name is self-explanatory\n",
    "z = np.random.randint(2, size=(len(dates_in_year)))\n",
    "text = [str(d) + '_' + str(i) for d,i in zip(data_days.values, dates_in_year)]\n",
    "\n",
    "colorscale=[[False, '#eeeeee'], [True, '#76cf63']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_revlog.kanji == '泉')\n",
    "z = list(mask.map(int))\n",
    "data_days = df_revlog.loc[:, 'cid'].groupby(pd.Grouper(freq='24H', base=4, label='left')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weeknumber_of_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "        go.Heatmap(\n",
    "            x = weeknumber_of_dates,\n",
    "            y = weekdays_in_year,\n",
    "            z = data_days,\n",
    "            text=text,\n",
    "            hoverinfo=\"text\",\n",
    "            xgap=3, # this\n",
    "            ygap=3, # and this is used to make the grid-like apperance\n",
    "            showscale=False,\n",
    "            colorscale=colorscale\n",
    "            )\n",
    "        ]\n",
    "\n",
    "layout = go.Layout(\n",
    "        title='activity chart',\n",
    "        height=280,\n",
    "        yaxis=dict(\n",
    "            showline = False, showgrid = False, zeroline = False,\n",
    "            tickmode=\"array\",\n",
    "            ticktext=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"],\n",
    "            tickvals=[0,1,2,3,4,5,6],\n",
    "            ),\n",
    "        xaxis=dict(\n",
    "            showline = False, showgrid = False, zeroline = False,\n",
    "            ),\n",
    "        font={\"size\":10, \"color\":\"#9e9e9e\"},\n",
    "        plot_bgcolor=(\"#fff\"),\n",
    "        margin = dict(t=40),\n",
    "        ) \n",
    "\n",
    "fig = go.FigureWidget(data=data, layout=layout)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw/kiritsubo.txt') as fp:\n",
    "    text = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('馬寮', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
